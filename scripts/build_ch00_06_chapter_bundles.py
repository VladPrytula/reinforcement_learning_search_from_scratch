#!/usr/bin/env python3
"""Build per-chapter (00-06) Markdown bundles with labs and solutions.

This script concatenates the authoritative chapter sources from `docs/book/ch00`
through `docs/book/ch06`, optionally sanitizing Unicode for LaTeX/PDF pipelines
via `scripts/sanitize_markdown_for_latex.py`.

It is intended for review packaging (e.g., a Springer submission bundle) where
each chapter should be readable as a single standalone Markdown file.
"""

from __future__ import annotations

import argparse
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Iterable


PROJECT_ROOT = Path(__file__).resolve().parent.parent

CHAPTER_SOURCES: dict[str, list[str]] = {
    "ch00": [
        "docs/book/ch00/ch00_motivation_first_experiment.md",
        "docs/book/ch00/exercises_labs.md",
        "docs/book/ch00/ch00_lab_solutions.md",
    ],
    "ch01": [
        "docs/book/ch01/ch01_foundations.md",
        "docs/book/ch01/exercises_labs.md",
        "docs/book/ch01/ch01_lab_solutions.md",
    ],
    "ch02": [
        "docs/book/ch02/ch02_probability_measure_click_models.md",
        "docs/book/ch02/exercises_labs.md",
        "docs/book/ch02/ch02_lab_solutions.md",
    ],
    "ch03": [
        "docs/book/ch03/ch03_stochastic_processes_bellman_foundations.md",
        "docs/book/ch03/exercises_labs.md",
        "docs/book/ch03/ch03_lab_solutions.md",
    ],
    "ch04": [
        "docs/book/ch04/ch04_generative_world_design.md",
        "docs/book/ch04/exercises_labs.md",
    ],
    "ch05": [
        "docs/book/ch05/ch05_relevance_features_reward.md",
        "docs/book/ch05/exercises_labs.md",
    ],
    "ch06": [
        "docs/book/ch06/discrete_template_bandits.md",
        "docs/book/ch06/exercises_labs.md",
        "docs/book/ch06/ch06_lab_solutions.md",
        "docs/book/ch06/ch06_advanced_gpu_lab.md",
    ],
}


def _iter_sources() -> Iterable[str]:
    seen: set[str] = set()
    for sources in CHAPTER_SOURCES.values():
        for src in sources:
            if src in seen:
                continue
            seen.add(src)
            yield src


def _rewrite_intra_chapter_links(text: str) -> str:
    # When bundling chapter text + exercises into one file, links like
    # `(./exercises_labs.md#lab-...)` should become intra-document anchors.
    return text.replace("](./exercises_labs.md#", "](#")


def _ensure_ascii(text: str, *, where: Path) -> None:
    try:
        text.encode("ascii")
    except UnicodeEncodeError as e:
        raise ValueError(f"Non-ASCII characters found in output: {where}") from e


def _sanitize_sources(output_dir: Path, sources: list[str]) -> None:
    sanitize_script = PROJECT_ROOT / "scripts" / "sanitize_markdown_for_latex.py"
    cmd = [sys.executable, str(sanitize_script), "--output-dir", str(output_dir), *sources]
    subprocess.run(cmd, cwd=PROJECT_ROOT, check=True)


def _write_bundle(
    *,
    chapter_id: str,
    sources: list[str],
    sanitized_root: Path,
    out_path: Path,
    title: str,
    author: str,
) -> None:
    out_path.parent.mkdir(parents=True, exist_ok=True)

    parts: list[str] = []
    parts.append("---\n")
    parts.append(f'title: "{title}"\n')
    parts.append(f'author: "{author}"\n')
    parts.append("---\n\n")
    parts.append(
        f"<!-- AUTOGENERATED: {chapter_id} bundle from docs/book/{chapter_id} (incl. labs + available solutions) -->\n\n"
    )

    for src in sources:
        sanitized_path = sanitized_root / src
        content = sanitized_path.read_text(encoding="utf-8")
        content = _rewrite_intra_chapter_links(content)
        parts.append(content)
        parts.append("\n\n")

    final = "".join(parts)
    _ensure_ascii(final, where=out_path)
    out_path.write_text(final, encoding="utf-8")


def main() -> int:
    ap = argparse.ArgumentParser(description="Build per-chapter Markdown bundles for Ch00â€“Ch06.")
    ap.add_argument(
        "--out-dir",
        default="docs/book/compiled/chapters_ch00-06",
        help="Output directory for chapter bundle markdown files.",
    )
    ap.add_argument(
        "--no-sanitize",
        action="store_true",
        help="Disable Unicode sanitization (not recommended for submission pipelines).",
    )
    ap.add_argument(
        "--author",
        default="Vlad Prytula",
        help="Author metadata for YAML front matter.",
    )
    ap.add_argument(
        "--title-prefix",
        default="Reinforcement Learning for Search from Scratch",
        help="Title prefix for YAML front matter.",
    )
    args = ap.parse_args()

    out_dir = (PROJECT_ROOT / args.out_dir).resolve()
    sources = list(_iter_sources())

    for src in sources:
        path = PROJECT_ROOT / src
        if not path.is_file():
            raise FileNotFoundError(f"Missing source file: {src}")

    with tempfile.TemporaryDirectory() as tmp:
        sanitized_root = Path(tmp)
        if args.no_sanitize:
            # Mirror sources into tmp so downstream logic is consistent.
            for src in sources:
                dst = sanitized_root / src
                dst.parent.mkdir(parents=True, exist_ok=True)
                dst.write_text((PROJECT_ROOT / src).read_text(encoding="utf-8"), encoding="utf-8")
        else:
            _sanitize_sources(sanitized_root, sources)

        for chapter_id, chapter_sources in CHAPTER_SOURCES.items():
            chapter_number = chapter_id.removeprefix("ch")
            title = f"{args.title_prefix} - Chapter {int(chapter_number)} (with Labs & Solutions)"
            out_path = out_dir / f"{chapter_id}_with_labs_and_solutions.md"
            _write_bundle(
                chapter_id=chapter_id,
                sources=chapter_sources,
                sanitized_root=sanitized_root,
                out_path=out_path,
                title=title,
                author=args.author,
            )

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
