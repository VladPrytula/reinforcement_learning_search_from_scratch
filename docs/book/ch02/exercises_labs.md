# Chapter 2 — Exercises & Labs (Application Mode)

Measure theory meets sampling: every probabilistic definition in Chapter 2 has a concrete simulator counterpart. Use these labs to validate the σ-algebra intuition numerically.

## Lab 2.1 — Segment Mix Sanity Check

Objective: verify that the empirical segment frequencies from `zoosim/world/users.py::sample_user` converge to the probability vector $\rho$ used in §2.3.

```python
import numpy as np
from zoosim.core import config
from zoosim.world import users

cfg = config.load_default_config()
rng = np.random.default_rng(21)
segments = [users.sample_user(config=cfg, rng=rng).segment for _ in range(10_000)]
unique, counts = np.unique(segments, return_counts=True)
empirical = counts / counts.sum()
theoretical = dict(zip(cfg.users.segments, cfg.users.segment_mix))
print("Empirical mix:", dict(zip(unique, empirical.round(3))))
print("Theoretical :", {seg: round(prob, 3) for seg, prob in theoretical.items()})
```

Example output (your numbers may differ slightly due to sampling):
```
Empirical mix: {'litter_heavy': 0.258, 'pl_lover': 0.254, 'premium': 0.153, 'price_hunter': 0.335}
Theoretical : {'litter_heavy': 0.25, 'pl_lover': 0.25, 'premium': 0.15, 'price_hunter': 0.35}
```

See `ch02_lab_solutions.md` (Lab 2.1) for a full, reproducible transcript generated by
`scripts/ch02/lab_solutions.py::lab_2_1_segment_mix_sanity_check` with the same seed and
configuration. Your run should match within Monte Carlo error (on the order of 1–2%).

**Tasks**
1. Repeat the experiment with different seeds and report the $\ell_\infty$ deviation $\|\hat{\rho} - \rho\|_\infty$; relate the result to the law of large numbers discussed in Chapter 2.
2. Modify `cfg.users.segment_mix` to create a degenerate distribution and document how this lab exposes the violation.

## Lab 2.2 — Query Measure and Base Score Integration

Objective: link the click-model measure $\mathbb{P}$ defined in §2.6 to simulator code paths.

```python
import numpy as np
from zoosim.core import config
from zoosim.world import catalog, queries, users
from zoosim.ranking import relevance

cfg = config.load_default_config()
rng = np.random.default_rng(3)
cat = catalog.generate_catalog(cfg.catalog, rng)
user = users.sample_user(config=cfg, rng=rng)
query = queries.sample_query(user=user, config=cfg, rng=rng)
scores = relevance.batch_base_scores(query=query, catalog=cat, config=cfg, rng=rng)
print(f"Base score mean: {np.mean(scores):.3f}")
print(f"Base score std : {np.std(scores):.3f}")
```

Output:
```
Base score mean: 0.512
Base score std : 0.207
```

**Tasks**
1. Replace the placeholder `user` with an actual draw from `users.sample_user` and confirm the statistics remain bounded as predicted by Proposition 2.8 on score integrability.
2. Push the histogram of `scores` into the chapter to make the Radon-Nikodym argument tangible (same figure can later fuel Chapter 5 when features are added).

## Lab 2.3 -- Textbook Click Model Verification

Objective: verify that toy implementations of PBM ([DEF-2.5.1], [EQ-2.1]) and DBN ([DEF-2.5.2], [EQ-2.3]) match their theoretical predictions exactly.

```python
import numpy as np

def simulate_pbm(relevance, exam_probs, n_sessions=10_000, seed=42):
    """
    PBM: P(C_k = 1) = rel(p_k) * theta_k  [EQ-2.1]
    Positions are independent given examination.
    """
    rng = np.random.default_rng(seed)
    M = len(relevance)
    examinations = rng.binomial(1, exam_probs, size=(n_sessions, M))
    clicks = examinations * rng.binomial(1, relevance, size=(n_sessions, M))
    return examinations, clicks

# Configuration: exponential decay examination
M = 10
exam_probs = np.array([0.9 * np.exp(-0.3 * k) for k in range(M)])
relevance = np.array([0.7 - 0.05 * k for k in range(M)])

_, clicks = simulate_pbm(relevance, exam_probs, n_sessions=50_000)
ctr_theory = relevance * exam_probs
ctr_empirical = clicks.mean(axis=0)

print("Position | Theory | Empirical | Error")
for k in range(M):
    print(f"   {k+1:2d}    | {ctr_theory[k]:.3f}  | {ctr_empirical[k]:.3f}     | {abs(ctr_theory[k] - ctr_empirical[k]):.4f}")
```

**Tasks**
1. Implement DBN and verify that examination decay follows [EQ-2.3]: $P(E_k = 1) = \prod_{j < k} [1 - \text{rel}(p_j) \cdot s(p_j)]$.
2. Compare PBM and DBN examination probabilities at position 5. Explain why DBN predicts higher examination for users who reach later positions.

## Lab 2.4 -- Nesting Verification ([PROP-2.5.4])

Objective: demonstrate that the Utility-Based Cascade Model (Section 2.5.4) reduces to PBM when utility weights are zeroed, verifying the **nesting property** from [PROP-2.5.4].

```python
import numpy as np
from zoosim.core.config import SimulatorConfig, BehaviorConfig
from zoosim.dynamics.behavior import simulate_session

# Create "PBM-like" configuration: disable utility weights and satisfaction dynamics
pbm_like_behavior = BehaviorConfig(
    alpha_price=0.0,   # Disable price sensitivity
    alpha_pl=0.0,      # Disable PL preference
    alpha_cat=0.0,     # Disable category preference
    sigma_u=0.0,       # No utility noise
    satisfaction_gain=0.0,
    satisfaction_decay=0.0,
    abandonment_threshold=-100.0,  # Never abandon due to satisfaction
    max_purchases=999,             # No purchase limit
    post_purchase_fatigue=0.0,
)

# Compare click patterns: should see position-only dependence (PBM-like)
# Full config vs PBM-like config
```

**Tasks**
1. Run 10,000 sessions with full BehaviorConfig and 10,000 with PBM-like config. Show that the PBM-like config produces click rates that depend only on position bias and relevance (independent of history), whereas the full config shows cascade effects.
2. Progressively re-enable utility weights ($\alpha_{\text{price}}$, then $\alpha_{\text{pl}}$, then $\alpha_{\text{cat}}$) and plot how the click probability surface changes from relevance-only (PBM) to utility-dependent (full model).

## Lab 2.5 -- Utility-Based Cascade Dynamics ([DEF-2.5.3])

Objective: verify the three key mechanisms of the production click model from Section 2.5.4: position decay, satisfaction dynamics, and stopping conditions.

```python
import numpy as np
from zoosim.core.config import SimulatorConfig
from zoosim.dynamics.behavior import simulate_session, SessionOutcome

cfg = SimulatorConfig()
rng = np.random.default_rng(42)

# Track satisfaction trajectories across sessions
n_sessions = 1000
session_lengths = []
final_satisfactions = []
abandonment_count = 0

for _ in range(n_sessions):
    # ... simulate session and track metrics
    pass

print(f"Mean session length: {np.mean(session_lengths):.1f}")
print(f"Abandonment rate: {100 * abandonment_count / n_sessions:.1f}%")
```

**Tasks**
1. Plot the satisfaction trajectory $S_k$ for 10 representative sessions. Identify sessions that ended due to: (a) examination failure, (b) satisfaction threshold crossing, (c) purchase limit.
2. Verify that the mean examination decay matches the position bias configuration from `BehaviorConfig.pos_bias`.
3. Modify `satisfaction_gain` and `satisfaction_decay` parameters. Document how this affects: session length distribution, abandonment rate, and total clicks per session.
