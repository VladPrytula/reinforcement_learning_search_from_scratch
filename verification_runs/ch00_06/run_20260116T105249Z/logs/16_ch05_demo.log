STEP 16/20: Ch05: Relevance/Features/Reward Demo
CMD: /Volumes/Lexar2T/src/reinforcement_learning_search_from_scratch/.venv/bin/python3 scripts/ch05/ch05_demo.py
CWD: /Volumes/Lexar2T/src/reinforcement_learning_search_from_scratch
START: 2026-01-16T10:54:22Z

================================================================================
CHAPTER 5 DEMONSTRATION: Relevance, Features, and Reward
================================================================================
================================================================================
PART 1: BASE RELEVANCE MODEL (Section 5.2)
================================================================================

User segment: pl_lover
Query category: 'cat_food' (type: category)

Top 10 products by base relevance:
Rank   PID      Category     Price    CM2      Score   
------------------------------------------------------------
1      5419     cat_food     $5.60    $0.17    0.648  
2      8204     cat_food     $10.67   $1.34    0.647  
3      8061     cat_food     $16.32   $1.79    0.638  
4      7736     cat_food     $11.74   $1.42    0.637  
5      2170     cat_food     $13.58   $1.37    0.627  
6      1985     cat_food     $9.16    $0.51    0.621  
7      5712     cat_food     $7.00    $0.79    0.620  
8      2544     cat_food     $8.92    $0.85    0.620  
9      2671     cat_food     $8.65    $0.44    0.614  
10     6263     cat_food     $8.89    $0.82    0.600  

[VALIDATION]
✓ Computed 10000 base scores
✓ Score range: [-0.324, 0.648]
✓ Mean score: 0.191
✓ Relevance weights: w_sem=0.7, w_lex=0.3


================================================================================
PART 2: FEATURE ENGINEERING (Section 5.3)
================================================================================

User segment: price_hunter
Query category: 'cat_food' (type: brand)

Features for top product (Product 7390):
Feature              Raw          Standardized
--------------------------------------------------
cm2                  1.665        0.378       
discount             0.103        1.092       
pl_flag              0.000        -0.816      
personalization      10.833       0.696       
bestseller           2.391        0.694       
price                14.122       0.570       
cm2_litter           0.000        0.000       
disc_price_sens      -0.313       -1.092      
pl_affinity          -0.000       0.816       
spec_bestseller      2.391        0.694       

[VALIDATION]
✓ Feature dimension: 10 (expected: 10)
✓ Standardized means (should be ~0): [-3.33066907e-16  1.11022302e-17 -7.77156117e-17] ...
✓ Standardized stds (should be ~1 for non-constant features): [1. 1. 1.] ...
✓ Constant features (std=0): [6]


================================================================================
PART 3: REWARD AGGREGATION (Section 5.5)
================================================================================

Simulated session:
  Ranking: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ...
  Clicks: [1, 1, 0, 1, 0, 0, 0, 1, 0, 0] ...
  Buys: [1, 0, 0, 1, 0, 0, 0, 0, 0, 0] ...

Reward breakdown:
  GMV: $15.45
  CM2: $1.13
  Strategic purchases: 1.0
  Clicks: 4

Scalarization [EQ-5.7]:
  1.0 × GMV = 15.45
  0.4 × CM2 = 0.45
  2.0 × Strategic = 2.00
  0.1 × Clicks = 0.40
  ──────────────────────────────
  Total reward: 18.31

[VALIDATION]
✓ Reward sum verified: 18.31
✓ Engagement safety ratio: 0.100 (must be in [0.01, 0.10])


================================================================================
PART 4: INTEGRATED EPISODE (Section 5.9)
================================================================================

User segment: price_hunter
Query category: 'cat_food' (type: generic)

[Step 1] Computing base relevance for all products...
✓ Ranked 10000 products, selected top 20

[Step 2] Extracting features for top 20 products...
✓ Computed 20 feature vectors (dim=10)

[Step 3] Agent applies boosts (random baseline)...
✓ Applied random boosts in [-0.1, +0.1]

[Step 4] User interaction (mock clicks/buys)...
✓ Clicks: 3, Purchases: 2

[Step 5] Computing reward...

Final reward breakdown:
  GMV: $20.19
  CM2: $2.15
  Strategic: 0.0
  Clicks: 3
  ──────────────────
  Total: 21.35

[VALIDATION]
✓ Complete episode executed: relevance → features → boosts → reward

================================================================================
SUMMARY
================================================================================
✓ All demonstrations completed successfully!

Key takeaways:
1. Base relevance: Hybrid semantic + lexical matching [EQ-5.3]
2. Features: 10-dimensional state representation with standardization [EQ-5.5]
3. Reward: Multi-objective scalarization with safety constraint [EQ-5.7]

Next steps:
- Chapter 6: Implement RL agents (LinUCB, Thompson Sampling)
- Chapter 7: Continuous action spaces (Q-learning for boosts)
- Chapter 10: Robustness and guardrails (CM2 floors, exposure guarantees)

For exercises and labs, see:
  docs/book/ch05/exercises_labs.md
================================================================================

